Step 1 Containerize and run the training of the ML model
see Dockerfile.train
Step 2 Containerize and run the serving of the ML model
see Dockerfile.infer

# i created a folder app with a subfolder models and copied the train.py and Server.py to the app folder
to ensure the containers were able to find the codes.

after the training container i see the model pickle file available in the models subfolder
after the serving of the container i could access localhost:8080 with the welcome message
and i could test the prediction of the model with a curl command (see dockerfile.infer)

i submitted the 2 images to docker hub
by first creating a tag for each image
and then use 
docker push ilseclv/train_ml:v01-amd64

on the HPC, i created a shell:
nano project_microcredential.sh 
see github for the file
and used SBATCH project_microcredential.sh
to submit the job

note i couldn't submit the job to donphan, my only option was doduo.

i saved the shell script and the slurm log onto github 

